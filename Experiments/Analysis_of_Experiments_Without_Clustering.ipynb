{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analysis_of_Experiments_Without-Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSRDZg6SxLwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3039a9b2-964a-4371-83a4-d56f657fdbd6"
      },
      "source": [
        "! git clone https://github.com/cggcaio/Anomaly-Detection-for-Driver-Identification.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Anomaly-Detection-for-Driver-Identification'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 572 (delta 35), reused 102 (delta 32), pack-reused 467\u001b[K\n",
            "Receiving objects: 100% (572/572), 61.02 MiB | 8.52 MiB/s, done.\n",
            "Resolving deltas: 100% (171/171), done.\n",
            "Checking out files: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixX_qvaTxfkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest # Importação Isolation Forest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import OneClassSVM # IMPORTAÇÃO OnClassSVM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiOAObgByK1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['ID','Method', 'Time_Window', 'Driver','Driver_B','Features', 'Method_Parameters', 'Accuracy_Train','Accuracy_Test','Accuracy_Anomaly', 'Inference_Time']\n",
        "results = pd.DataFrame(columns=columns)\n",
        "\n",
        "# new_row = [\"ON-SVM\", 32, \"A\", \"Teste\", \"Teste\", 95.3]\n",
        "# Analysis_df = Analysis_df.append(pd.DataFrame([new_row],columns=columns))\n",
        "\n",
        "# Features:\n",
        "# Iap - Intake_air_pressure\n",
        "# Est - Engine_soacking_time\n",
        "# LTFTB - Long_Term_Fuel_Trim_Bank1\n",
        "# Tof - Torque_of_friction\n",
        "# Ect - Engine_coolant_temperature\n",
        "# Swp - Steering_wheel_speed                      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zecTON_smE7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(driver_id,window_size):\n",
        "\n",
        "  t = window_size\n",
        "  d_s = driver_id\n",
        "  # Reading the selected driver\n",
        "  path = '/content/Anomaly-Detection-for-Driver-Identification/Data_Bases/Organized_DB2/Driver_'+d_s+'/driver_'+d_s+'_block_'+str(t)+'s'\n",
        "  df = pd.read_csv(path, sep=\",\")\n",
        "  print(\"\")\n",
        "  print(\"DRIVER \"+d_s+\" SELECTED IN THE TIME WINDOW \"+str(t))\n",
        "\n",
        "  # Creating a row of ones\n",
        "  labels = np.ones((df.shape[0],1))\n",
        "\n",
        "  # Randomly shuffle all entries to avoid anomalous data blocks.\n",
        "  for f in range(0, 3):\n",
        "    df = df.iloc[np.random.permutation(len(df))] \n",
        "\n",
        "  # Scikit-learn function called train_test_split that divide the data between train and test.\n",
        "  x_train, x_val, y_train, y_val = train_test_split(df, labels, test_size = 0.2, random_state = 42) \n",
        "  return {'x_train':x_train, 'x_val': x_val, 'y_train':y_train, 'y_val':y_val}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayj_0xmCGisk",
        "colab_type": "text"
      },
      "source": [
        "## Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qm34bJpjhVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IFTraining(x_train,max_samples=256,n_estimators=1000,contamination=0.002):\n",
        "\n",
        "  # Defining the algorithm paramathers\n",
        "  isolation_forest = IsolationForest(n_estimators=n_estimators, max_samples=max_samples, contamination=contamination, random_state=42)\n",
        "  # n_estimators is the number of trees to use in forest. Default is 100.\n",
        "  # max_samples is the maximum number of data points that the tree should build on. Default is 256 or smaller\n",
        "  # contamination is an estimate of the percentage of the entire data set that should be considered an anomaly. Default is 0.1\n",
        "  # random_state is the number it will initialize the random number generator with to use during the training process.\n",
        "\n",
        "  isolation_forest.fit(x_train)\n",
        "\n",
        "  return isolation_forest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MISxjXEiocd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_threshold(iso_forest,x_val):\n",
        "    anomaly_scores_test = iso_forest.decision_function(x_val)\n",
        "    threshold = 0\n",
        "    anomalies_test = anomaly_scores_test > 0                  \n",
        "    num_false = np.sum([1 for a in anomalies_test if not a])\n",
        "    res = num_false/len(anomalies_test)\n",
        "\n",
        "    while (res>0.001):\n",
        "      threshold = threshold - 0.001\n",
        "      anomalies_test = anomaly_scores_test > threshold \n",
        "      num_false = np.sum([1 for a in anomalies_test if not a])\n",
        "      res = num_false/len(anomalies_test)\n",
        "    return threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONBVSnu9qbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def executeIF(isolation_forest,x_train,x_val,new_driver,t):\n",
        "\n",
        "  # Compute threshold\n",
        "  threshold = compute_threshold(iso_forest,x_train)\n",
        "\n",
        "  # Compute acc_train\n",
        "\n",
        "  acc_train = get_accuracy_iso(x_train,isolation_forest,threshold)\n",
        "\n",
        "  # Compute acc_test\n",
        "\n",
        "  acc_test = get_accuracy_iso(x_val,isolation_forest,threshold)\n",
        "\n",
        "  # acc_an\n",
        "\n",
        "  path = '/content/Anomaly-Detection-for-Driver-Identification/Data_Bases/Organized_DB2/Driver_'+new_driver+'/driver_'+new_driver+'_block_'+str(t)+'s'\n",
        "  dfb = pd.read_csv(path, sep=\",\") \n",
        "  x = dfb.to_numpy()\n",
        "  acc_an = get_accuracy_iso(x,isolation_forest,threshold)\n",
        "\n",
        "  return {'acc_train':acc_train['acc'],'acc_test':acc_test['acc'],'acc_an': 1 - acc_an['acc'],'inf_time':acc_an['inf_time']}\n",
        "\n",
        "\n",
        "def get_accuracy_iso(x,isolation_forest,threshold):\n",
        "  \n",
        "  ini = time.time()\n",
        "  scores_val = isolation_forest.decision_function(x)\n",
        "  fin = time.time() \n",
        "  \n",
        "  anomalies = scores_val < threshold \n",
        "  num_false = np.sum([1 for a in anomalies if a])\n",
        "  return {'acc': 1 - (num_false/len(anomalies)), 'inf_time': (fin-ini)/x.shape[0]}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqw4THc5GXaN",
        "colab_type": "text"
      },
      "source": [
        "## OC-SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d3eMSKlBBbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def OCSVMTraining(x_train, kernel, nu):\n",
        "  ocsvm = OneClassSVM(kernel=kernel, nu=nu)\n",
        "\n",
        "  ocsvm.fit(x_train)\n",
        "  \n",
        "  return ocsvm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5R5bDc992WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def executeOCSVM(ocsvm,x_train,x_val,new_driver,t):\n",
        "  \n",
        "  # Compute acc_train\n",
        "  acc_train = get_accuracy_ocsvm(ocsvm, x_train)\n",
        "  \n",
        "  # Compute acc_test\n",
        "  acc_test = get_accuracy_ocsvm(ocsvm, x_val)\n",
        "\n",
        "  # acc_an\n",
        "  path = '/content/Anomaly-Detection-for-Driver-Identification/Data_Bases/Organized_DB2/Driver_'+new_driver+'/driver_'+new_driver+'_block_'+str(t)+'s'\n",
        "  dfb = pd.read_csv(path, sep=\",\") \n",
        "  x = dfb.to_numpy()\n",
        "  acc_an = get_accuracy_ocsvm(ocsvm, x)\n",
        "\n",
        "  return {'acc_train':acc_train['acc'],'acc_test':acc_test['acc'],'acc_an': 1 - acc_an['acc'],'inf_time':acc_an['inf_time']}\n",
        "\n",
        "def get_accuracy_ocsvm(ocsvm, x):\n",
        "  ini = time.time()\n",
        "  preds = ocsvm.predict(x)\n",
        "  fin = time.time()\n",
        "\n",
        "  score = 0\n",
        "  for f in range(0, x.shape[0]):\n",
        "    if(preds[f] == 1):\n",
        "        score = score+1\n",
        "  acc = score / x.shape[0]\n",
        "\n",
        "  return {'acc':acc, 'inf_time': (fin-ini)/x.shape[0]}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIftbguB6hyJ",
        "colab_type": "text"
      },
      "source": [
        "## Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEQ0OY5R0l8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "id_ = 0\n",
        "features = ['Iap','Est', 'LTFTB', 'Tof', 'Ect', 'Swp']\n",
        "\n",
        "methods = ['OCSVM']\n",
        "time_window = [30]\n",
        "driver = ['A','B','C','D','E','F','G','H']\n",
        "nexp = 5\n",
        "\n",
        "\n",
        "# IS params\n",
        "max_samples = [256]\n",
        "n_estimators = [1000]\n",
        "contamination = [0.002]\n",
        "\n",
        "# OSVM\n",
        "kernels = ['sigmoid'] #rbf\n",
        "nu = [0.0001]\n",
        "\n",
        "for m in methods:\n",
        "  for tw in time_window:\n",
        "    for d in tqdm(driver):\n",
        "      if m == 'IF':\n",
        "        for ms in max_samples:\n",
        "          for ne in n_estimators:\n",
        "            for c in contamination:\n",
        "              for j in range(nexp):\n",
        "\n",
        "                # Get data \n",
        "                data = split_data(d,tw)\n",
        "\n",
        "                # Model training\n",
        "                iso_forest = IFTraining(data['x_train'],ms,ne,c) \n",
        "\n",
        "                # ['ID','Method', 'Time_Window', 'Driver','Driver_B' 'Features', 'Method_Parameters', 'Accuracy_Train','Accuracy_Test','Accuracy_Anomaly', 'Inference_Time']\n",
        "                for driver_b in driver: \n",
        "                  # executar\n",
        "                  if driver_b != d:\n",
        "                    response = executeIF(iso_forest,data['x_train'],data['x_val'],driver_b,tw)\n",
        "                    row = [j,m,tw,d,driver_b,str(features), str({'max_samples':ms,'n_estimators':ne,'contamination':c}), response['acc_train'], response['acc_test'],response['acc_an'], response['inf_time']]\n",
        "\n",
        "                    df = pd.DataFrame([row],columns=columns)\n",
        "\n",
        "                    results = results.append(df)\n",
        "                    results.to_csv('results.csv')\n",
        "      if m == 'OCSVM':\n",
        "        for k in kernels:\n",
        "          for n in nu:\n",
        "            for j in range(nexp):\n",
        "              # Get data\n",
        "              data = split_data(d,tw)\n",
        "\n",
        "              # Model Training\n",
        "              onclass = OCSVMTraining(data['x_train'],k,n)\n",
        "\n",
        "              # ['ID','Method', 'Time_Window', 'Driver','Driver_B' 'Features', 'Method_Parameters', 'Accuracy_Train','Accuracy_Test','Accuracy_Anomaly', 'Inference_Time']\n",
        "              for driver_b in driver:\n",
        "                if driver_b != d:\n",
        "                  response = executeOCSVM(onclass,data['x_train'],data['x_val'], driver_b, tw)\n",
        "                  row = [j,m,tw,d,driver_b,str(features), str({'kernels':k, 'nu':n}), response['acc_train'], response['acc_test'],response['acc_an'], response['inf_time']]\n",
        "\n",
        "                  df = pd.DataFrame([row], columns=columns)\n",
        "                  results = results.append(df)\n",
        "                  results.to_csv('results.csv')\n",
        "\n",
        "\n",
        "                  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}